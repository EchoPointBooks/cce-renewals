#!/usr/bin/env python3 -u

import argparse
from collections import defaultdict
import csv
import dateutil.parser
import lxml.etree as ET
import re
import sys
import uuid

PARSE_REGNUM = re.compile(r'^([^0]+)(\d+)$')
DATE_RE = r'\d{1,2}[A-z]{3}\d{1,2}'
ONE_DATE = re.compile(DATE_RE)
REGNUM_RE = r'(?:A(?:(?:A|F|IO?\-|5\-|6\-|O-))?|B(?:5\-)?|DP|I(?:U)?|[CDFGJKL]|Label |Print )\d+(?:\-\d+)?'
ONE_REGNUM = re.compile(REGNUM_RE)

PUB_ABR = re.compile(r'^(.*?)({}), ({})(.*)'.format(DATE_RE, REGNUM_RE))


def hyphenize(c):
    """Add a hyphen to the regnum class if it ends in a digit, (e.g. B5-)."""
    return c + '-' if c[-1].isdigit() else c


def parse_date(d):
    try:
        dt = dateutil.parser.parse(d)
        if dt.year > 2000:
            return (dt - dateutil.relativedelta.relativedelta(years=100)).strftime('%Y-%m-%d')
    
        return dt.strftime('%Y-%m-%d')
    except ValueError:
        # Not all the dates are valid
        return None

def reg_regnum(r):
    m = PARSE_REGNUM.match(r)
    if m:
        return '{:s}{:d}'.format(hyphenize(m[1]), int(m[2]))
    return r


def regularize_regnums(regnums, k):
    return {k: '|'.join([reg_regnum(r) for r in regnums[k].split('|')])}


def regularize(d):
    """Return a new dict with some of the fields regularized."""
    return {**d,
            **regularize_regnums(d, 'oreg'),
            **regularize_regnums(d, 'id')}



def format_holders(holders):
    return {'claimants': '||'.join(
        ['|'.join((h.find('Name').text, h.find('Type').text))
         for h in holders])}


def get_claimaints(d, rec):
    """Use claimants from the parsed XML"""
    return {**d,
            **format_holders(rec.findall('Holder'))}


def add_uuid(d, record):
    """Use the records MD5Sum element as a UUID."""
    return {**d,
            **{'entry_id': str(uuid.UUID(record.find('MD5Sum').text))}}
    

def handle_prev_pub(d):
    if 'note' in d:
        notes = [d['note']]
    else:
        notes = []
    prev = []
    if 'publ' in d:
        for pub in re.split(r';\s*', d['publ']):
            m = PUB_ABR.search(pub)
            if m:
                prev += [[parse_date(m[2].strip()), m[3].strip()]]
                notes += [pub]
            else:
                notes += [pub]

        return ({**d,
                 **{'note': '|'.join(notes)}},
                prev)
    return (d, [])



def validate_date(d):
    try:
        dateutil.parser.parse(d)
        return d
    except ValueError:
        # Not all the dates are valid
        return None
    


def validate(dd):
    return {**dd,
            **{'odat': validate_date(dd['odat'])}}


def output(dd, writer):

    reg_nums = dd['oreg'].split('|')
    reg_dates = dd['odat'].split('|')
    
    if len(reg_nums) == len(reg_dates):
        for reg in zip(reg_nums, dd['odat'].split('|')):
            writer.writerow(validate({**dd,
                                      **{'oreg': reg[0], 'odat': reg[1]}}))
    else:
        raise Exception('Unbalanced number of reg numbers/dates')
    

parser = argparse.ArgumentParser(description='Read Google Renewals')
parser.add_argument('-f', '--file', metavar='XML', type=argparse.FileType('r'),
                    help='XML file to process')
parser.add_argument('-y', '--year', metavar='YEAR', help='Year to filter')
args = parser.parse_args()


tree = ET.parse(args.file)
root = tree.getroot()

fieldnames = ('entry_id', 'volume', 'part','number', 'page', 'auth', 'titl', 'oreg', 'odat', 'id', 'dreg', 'claimants', 'new_matter', 'see_also_ren', 'see_also_reg', 'note', 'full_text')


writer = csv.DictWriter(sys.stdout, fieldnames=fieldnames,
                        delimiter='\t', extrasaction='ignore', restval=None)
writer.writeheader()

for record in root.findall('./Record'):
    if 'web-%s' % args.year in record.find('File').text:

        fields = [f.split(':\t') for f in record.find('Snippet').text.split('\n') if f != '']

        d = defaultdict(list)
        for k, v in fields:
            d[k.lower()].append(v)

        
        
        dd = dict([(b[0],'|'.join(b[1])) for b in d.items()])
        dd = get_claimaints(dd, record)
        (dd, prev) = handle_prev_pub(dd)
        dd = add_uuid(dd, record)
        output(regularize(dd), writer)
        for p in prev:
            output({**regularize(dd), **{'odat': p[0], 'oreg': p[1]}}, writer)

        
    
